{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_ft = pd.read_csv('features_n_target.csv')\n",
    "df_ft.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    " 'monetary_DNN',\n",
    " 'frequency_DNN',\n",
    " 'frequency',\n",
    " 't',\n",
    " 'time_between',\n",
    " 'avg_basket_value',\n",
    " 'avg_basket_size',\n",
    " 'cnt_returns',\n",
    " 'has_returned']\n",
    "numeric_f = ['monetary_DNN','frequency_DNN','frequency','t',\n",
    "              'time_between','avg_basket_value','avg_basket_size','cnt_returns']\n",
    "cate_f = ['has_returned']\n",
    "\n",
    "target = ['target_monetary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_full,X_test,y_train_full,y_test = train_test_split(df_ft[features],df_ft[target],test_size = 0.2,random_state = 42)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train_full,y_train_full,test_size = 0.15, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "train_num,train_cate = X_train[:,:-1],X_train[:,-1]\n",
    "valid_num,valid_cate = X_valid[:,:-1],X_valid[:,-1]\n",
    "test_num,test_cate = X_test[:,:-1],X_test[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widendeep_model(x_train,y_train,x_valid,y_valid,params):\n",
    "\n",
    "    input_num = tf.keras.layers.Input(shape = (8,),name = 'deep_input')\n",
    "    input_cate= tf.keras.layers.Input(shape = (1,),name = 'wide_input')\n",
    "\n",
    "\n",
    "    hidden_= tf.keras.layers.Dense(params['units'],\n",
    "                           kernel_initializer = params['initial'], \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.01))(input_num)\n",
    "    hidden_ = tf.keras.layers.BatchNormalization()(hidden_)\n",
    "    hidden_ = tf.keras.activations.relu(hidden_)\n",
    "    \n",
    "    \n",
    "    hidden_ = tf.keras.layers.Dense(params['units'],\n",
    "                       kernel_initializer = params['initial'], \n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.01))(hidden_)\n",
    "    hidden_ = tf.keras.layers.BatchNormalization()(hidden_)\n",
    "    hidden_ = tf.keras.activations.relu(hidden_)\n",
    "    hidden_ = tf.keras.layers.Dropout(params['dropout'])(hidden_)\n",
    "\n",
    "\n",
    "    concat = tf.keras.layers.concatenate([input_cate,hidden_])\n",
    "    output = tf.keras.layers.Dense(1,name = 'output')(concat)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [input_cate,input_num],outputs=[output])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = params['learning_rate'],beta_1=0.9, beta_2=0.999)\n",
    "    metrics = tf.keras.metrics.RootMeanSquaredError()\n",
    "    model.compile(optimizer = optimizer,loss='mse',metrics=metrics)\n",
    "\n",
    "    out = model.fit(x= x_train,\n",
    "                    y= y_train,\n",
    "                    validation_data=[x_valid,y_valid],\n",
    "                    epochs=150,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "    \n",
    "    return out,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "# from keras.utils import plot_model\n",
    "from scipy.stats import reciprocal\n",
    "input_shape=[8,1]\n",
    "learning_rate=reciprocal(3e-4,3e-2).rvs(100).tolist()\n",
    "units = [128,64,32,16]\n",
    "initial =['lecun_normal','glorot_uniform','he_normal']\n",
    "batch_size=[12,16,20]\n",
    "dropout = [0.1,0.15,0.2,0.25]\n",
    "\n",
    "params = {'units':units,\n",
    "         'initial':initial,\n",
    "         'learning_rate':learning_rate,\n",
    "         'batch_size':batch_size,\n",
    "         'dropout':dropout} \n",
    "\n",
    "\n",
    "scan_object = talos.Scan(x=[X_train[:,8].reshape(-1,1),X_train[:,:8]],\n",
    "                         y=y_train,\n",
    "                         x_val=[X_valid[:,8].reshape(-1,1),X_valid[:,:8]],\n",
    "                         y_val=y_valid,\n",
    "                         params=params,\n",
    "                         model=widendeep_model,experiment_name='try')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "units_list = [[128,64],[64,64],[64,32],[32,32],[32,16],[16,16]]\n",
    "learning_rates=reciprocal(3e-4,3e-2).rvs(100).tolist()\n",
    "dropout =0.15\n",
    "batch_size = 12\n",
    "params_history = []\n",
    "for units in units_list:\n",
    "    for learning_rate in learning_rates:\n",
    "        model = widendeep_model(units,learning_rate)\n",
    "        history = model.fit((train_cate.reshape(-1,1),train_num), \n",
    "                            y_train, \n",
    "                            epochs=200, \n",
    "                            shuffle=True,\n",
    "                            batch_size = batch_size,\n",
    "                            validation_data = ((valid_cate.reshape(-1,1),valid_num),y_valid),\n",
    "                            callbacks=[earlystop]\n",
    "         )\n",
    "        params_history.append([units,learning_rate,history.history['val_root_mean_squared_error']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(params_history,columns=['units','learning_rate','loss'])\n",
    "min_loss = np.zeros(len(df))\n",
    "for i in range(len(df)):\n",
    "    loss = min(df.loss[i])\n",
    "    min_loss[i] = loss\n",
    "inx = np.argmin(min_loss)\n",
    "print('optimal units:',df.iloc[inx,0],\n",
    "     '\\noptimal learning rate:',df.iloc[inx,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the multiple imput model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras_tuner as kt\n",
    "# from keras_tuner import RandomSearch\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "\n",
    "def widendeep_model(units,learning_rate):\n",
    "\n",
    "    input_num = tf.keras.layers.Input(shape = [8],name = 'deep_input')\n",
    "    input_cate= tf.keras.layers.Input(shape = [1],name = 'wide_input')\n",
    "\n",
    "\n",
    "    hidden_= tf.keras.layers.Dense(units[0],\n",
    "                           kernel_initializer = 'lecun_normal', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.01))(input_num)\n",
    "    hidden_ = tf.keras.layers.BatchNormalization()(hidden_)\n",
    "    hidden_ = tf.keras.activations.relu(hidden_)\n",
    "    \n",
    "    \n",
    "    hidden_ = tf.keras.layers.Dense(units[1],\n",
    "                       kernel_initializer ='lecun_normal', \n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.01))(hidden_)\n",
    "    hidden_ = tf.keras.layers.BatchNormalization()(hidden_)\n",
    "    hidden_ = tf.keras.activations.relu(hidden_)\n",
    "    hidden_ = tf.keras.layers.Dropout(dropout)(hidden_)\n",
    "\n",
    "\n",
    "    concat = tf.keras.layers.concatenate([input_cate,hidden_])\n",
    "    output = tf.keras.layers.Dense(1,name = 'output')(concat)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [input_cate,input_num],outputs=[output])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate,beta_1=0.9, beta_2=0.999)\n",
    "    metrics = tf.keras.metrics.RootMeanSquaredError()\n",
    "    model.compile(optimizer = optimizer,loss='mse',metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# tensorboard = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(patience=100,\n",
    "                                          restore_best_weights=True)\n",
    "\n",
    "units = [64, 64]\n",
    "learning_rate = 0.00232087319077393\n",
    "dropout =0.15\n",
    "batch_size = 12\n",
    "\n",
    "model = widendeep_model(units,learning_rate)\n",
    "model.fit((train_cate.reshape(-1,1),train_num), y_train, epochs=300, shuffle=True,\n",
    "          batch_size = batch_size,\n",
    "                    validation_data = ((valid_cate.reshape(-1,1),valid_num),y_valid),\n",
    "                     callbacks=[earlystop]\n",
    "         )\n",
    "mse_test = model.evaluate((test_cate.reshape(-1,1),test_num), y_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root Mean Squared Error:', mse_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
